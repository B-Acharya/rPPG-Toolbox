{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import h5py\n",
    "from pathlib import Path\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import mediapy as media\n",
    "import pickle\n",
    "import sys\n",
    "#You may have to change this path to work with your rPPG-toolbox path\n",
    "sys.path.append(\"/homes/bacharya/rPPG-Toolbox/\")\n",
    "from evaluation.post_process import calculate_HR\n",
    "from scipy.sparse import spdiags\n",
    "from scipy.signal import butter\n",
    "import scipy\n",
    "import heartpy\n",
    "from unsupervised_methods.unsupervised_predictor import ecg_processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2badb02e-42ae-43e4-a176-4e25a8ac6433",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = Path(\"/data/dst_tsst_22_bi_multi_nt_lab/processed/rPPG/DST_SizeW72_SizeH72_ClipLength180_DataTypeRaw_DataAugNone_LabelTypeRaw_Crop_faceTrue_Large_boxTrue_Large_size1.5_Dyamic_DetTrue_det_len1_Median_face_boxFalse_unsupervised/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d880125-cd6a-4f30-862a-8f3fefd5d081",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = list(paths.rglob(\"*input*.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aad0753-0e10-4937-abf9-e117a29461d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf5c347-5655-4174-bb45-278e172f761e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "size = [72, 72]\n",
    "fps = 30\n",
    "#save the video created from numpy files ( maybe theres a more direct way to plot them ?) \n",
    "for path in paths:\n",
    "    name = path.stem\n",
    "    print(name)\n",
    "    out = cv2.VideoWriter(f'{name}.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (size[1], size[0]), True)\n",
    "    data = np.uint8( np.load(path))\n",
    "    for i in range(data.shape[0]):\n",
    "        out.write(data[i,:,:,::-1])\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be3a21a-8dc7-4392-861a-d8cb4cd7d015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video, display\n",
    "from ipywidgets import Output, GridspecLayout\n",
    "\n",
    "videoPaths = list(Path(\".\").rglob(\"*input0.mp4\"))\n",
    "videos = []\n",
    "for path in videoPaths:\n",
    "    videos.append(media.read_video(path))\n",
    "media.show_videos(videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48b7f83-34ce-42aa-91f7-e51b30107618",
   "metadata": {},
   "source": [
    "Most videos are good. However, there are a few exceptions that exist and would be interesting to look at these individual videos and see what the performance of the methods. \n",
    "The background for some are different even though they are cropped.\n",
    "TODO: plotting the signal with the video makes sense to see the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f671790-2700-4abb-9f62-f0be957a3b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def _reform_data_from_dict(data, flatten=True):\n",
    "    \"\"\"Helper func for calculate metrics: reformat predictions and labels from dicts. \"\"\"\n",
    "    # sort_data = sorted(data.items(), key=lambda x: x[0])\n",
    "    # sort_data = [i[1] for i in sort_data]\n",
    "    # sort_data = torch.cat(sort_data, dim=0)\n",
    "\n",
    "    if flatten:\n",
    "        sort_data = np.reshape(data, (-1))\n",
    "    else:\n",
    "        sort_data = np.array(data)\n",
    "\n",
    "    return sort_data\n",
    "\n",
    "def _process_signal(signal, fs=30, diff_flag=True):\n",
    "    # Detrend and filter\n",
    "    use_bandpass = True\n",
    "    if diff_flag:  # if the predictions and labels are 1st derivative of PPG signal.\n",
    "        gt_bvp = _detrend(np.cumsum(signal), 100)\n",
    "    else:\n",
    "        gt_bvp = _detrend(signal, 100)\n",
    "    if use_bandpass:\n",
    "        # bandpass filter between [0.75, 2.5] Hz\n",
    "        # equals [45, 150] beats per min\n",
    "        [b, a] = butter(1, [0.75 / fs * 2, 2.5 / fs * 2], btype='bandpass')\n",
    "        signal = scipy.signal.filtfilt(b, a, np.double(signal))\n",
    "    return signal\n",
    "\n",
    "def _detrend(input_signal, lambda_value):\n",
    "    \"\"\"Detrend PPG signal.\"\"\"\n",
    "    signal_length = input_signal.shape[0]\n",
    "    # observation matrix\n",
    "    H = np.identity(signal_length)\n",
    "    ones = np.ones(signal_length)\n",
    "    minus_twos = -2 * np.ones(signal_length)\n",
    "    diags_data = np.array([ones, minus_twos, ones])\n",
    "    diags_index = np.array([0, 1, 2])\n",
    "    D = spdiags(diags_data, diags_index,\n",
    "                (signal_length - 2), signal_length).toarray()\n",
    "    detrended_signal = np.dot(\n",
    "        (H - np.linalg.inv(H + (lambda_value ** 2) * np.dot(D.T, D))), input_signal)\n",
    "    return detrended_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d7fc64-66bc-488e-b179-30af5187677e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the signal\n",
    "data_out_path = \"/data/dst_tsst_22_bi_multi_nt_lab/processed/rPPG/DST_SizeW72_SizeH72_ClipLength180_DataTypeRaw_DataAugNone_LabelTypeRaw_Crop_faceTrue_Large_boxTrue_Large_size1.5_Dyamic_DetTrue_det_len1_Median_face_boxFalse_unsupervised/CHROM_outputs.pickle\"  # Output Data Path \n",
    "trial_idx = 0\n",
    "chunk_size = 1800 # size of chunk to visualize: -1 will plot the entire signal\n",
    "chunk_num = 0\n",
    "\n",
    "# Read in data and list subjects\n",
    "with open(data_out_path, 'rb') as f:\n",
    "    # print(f.readlines())\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "# List of all video trials\n",
    "trial_list = list(data['predictions'].keys())\n",
    "print('Num Trials', len(trial_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40e03d3-3048-47a2-9ff5-0802b0d4d2a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot all the figures\n",
    "for i in range(len(trial_list)):\n",
    "    trial_idx = i\n",
    "    participant_id = trial_list[trial_idx]\n",
    "    \n",
    "    prediction = np.array(data['predictions'][trial_list[trial_idx]])\n",
    "    label = np.array(data['labels'][trial_list[trial_idx]])\n",
    "    \n",
    "    # prediction = np.array(data['predictions'][trial_idx])\n",
    "    \n",
    "    # Read in meta-data from pickle file\n",
    "    # fs = data['fs'] # Video Frame Rate\n",
    "    fs = 25\n",
    "    label_type = data['label_type'] # PPG Signal Transformation: `DiffNormalized` or `Standardized`\n",
    "    diff_flag = (label_type == 'DiffNormalized')\n",
    "    print(fs)\n",
    "    if chunk_size == -1:\n",
    "        chunk_size = len(prediction)\n",
    "        chunk_num = 0\n",
    "\n",
    "    label_frame_size = len(label)\n",
    "    if label_frame_size>25000 and label_frame_size<30000:\n",
    "        sampling_rate = 300\n",
    "    else:\n",
    "        sampling_rate = 1000\n",
    "    gt_hr = ecg_processing(label, sampling_rate, plot_hp=True)\n",
    "    print(\"Pred HR\",calculate_HR(prediction, fs=fs))\n",
    "    print(\"GT HR\", gt_hr)\n",
    "    print(participant_id, i )\n",
    "    \n",
    "    #process videos and visualize them\n",
    "    path = f'./' + f'{participant_id}_input0.mp4' \n",
    "    video = media.read_video(path)\n",
    "    # print(\"Number of frames\", video.shape[0])\n",
    "    print(\"Length of video\", video.shape[0]/fs)\n",
    "    media.show_video(video)\n",
    "    # Process label and prediction signals\n",
    "    prediction = _process_signal(prediction, fs, diff_flag=diff_flag)\n",
    "    # label = _process_signal(label, fs, diff_flag=diff_flag)\n",
    "    # start = (chunk_num)*chunk_size\n",
    "    # stop = (chunk_num+1)*chunk_size\n",
    "    samples = len(prediction)\n",
    "    x_time = np.linspace(0, samples/fs, num=samples)\n",
    "    \n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(x_time, prediction, color='r')\n",
    "    plt.title('Trial: ' + trial_list[trial_idx])\n",
    "    plt.legend(['Predictions', 'Labels'])\n",
    "    plt.xlabel('Time (s)');\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fbd5e6-cc18-4505-a736-2fd1298353a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e1599b-27f8-4c86-aaad-8fc9e51db11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interactive video viewer\n",
    "\n",
    "from ipywidgets import interactive\n",
    "\n",
    "\n",
    "trail_idx = 0\n",
    "participant_id = trial_list[trial_idx]\n",
    "prediction = np.array(data['predictions'][trial_list[trial_idx]])\n",
    "diff_flag = (label_type == 'DiffNormalized')\n",
    "path = f'./' + f'{participant_id}_input0.mp4' \n",
    "video = media.read_video(path)\n",
    "\n",
    "def f(time):\n",
    "    if time <=4:\n",
    "        x = x_time[0:8*fs]\n",
    "        pred = prediction[0:8*fs]\n",
    "        vid = video[0:8*fs]\n",
    "    else:\n",
    "        x = x_time[(time-4)*fs:(time+4)*fs]\n",
    "        pred = prediction[(time-4)*fs:(time+4)*fs]\n",
    "        vid = video[(time-4)*fs:(time+4)*fs]\n",
    "    \n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(x, pred, color='r')\n",
    "    # plt.title('Trial: ' + trial_list[trial_idx])\n",
    "    plt.legend(['Predictions', 'Labels'])\n",
    "    plt.xlabel('Time (s)')\n",
    "    media.show_video(vid)\n",
    "\n",
    "interactive_plot = interactive(f, time=(0, len(prediction)//fs - 2))\n",
    "output = interactive_plot.children[-1]\n",
    "output.layout.height = '300px'\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d0d5c0-e978-442b-98e2-6f326934d4de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
